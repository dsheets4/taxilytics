{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Shenzhen Data\n",
    "We where provided several days worth of data for Shenzhen.  At first glance this data seems to be very clean.  This notebook goes through some of the initial processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "There are several things we can determine from a quick inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python libraries\n",
    "from datetime import datetime\n",
    "import os, io\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Custom Code\n",
    "from entity.loader.taxi.taxi_common import (\n",
    "    sample_df,\n",
    "    human_size,\n",
    "    remove_safe_dups,\n",
    "    remove_impossible,\n",
    "    remove_implausible,\n",
    ")\n",
    "from processing.coordinates import wgs2gcj, gcj2wgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Files and Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Day_Of_Week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-09-15</th>\n",
       "      <td>493.9M</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-16</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-17</th>\n",
       "      <td>1.9G</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-18</th>\n",
       "      <td>2.0G</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-19</th>\n",
       "      <td>1.7G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-20</th>\n",
       "      <td>2.2G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-21</th>\n",
       "      <td>388.6M</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-23</th>\n",
       "      <td>1.0G</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-24</th>\n",
       "      <td>2.0G</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-25</th>\n",
       "      <td>2.0G</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-26</th>\n",
       "      <td>1.9G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-27</th>\n",
       "      <td>1.7G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-28</th>\n",
       "      <td>1.7G</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-29</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>1.9G</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-02</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-03</th>\n",
       "      <td>1.7G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-04</th>\n",
       "      <td>1.6G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-06</th>\n",
       "      <td>836.8M</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-09</th>\n",
       "      <td>46.7M</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-10</th>\n",
       "      <td>1.2G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-11</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-12</th>\n",
       "      <td>1.6G</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-13</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-14</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-15</th>\n",
       "      <td>1.8G</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-16</th>\n",
       "      <td>1.6G</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-17</th>\n",
       "      <td>1.2G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-18</th>\n",
       "      <td>1.5G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-19</th>\n",
       "      <td>2.3G</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-20</th>\n",
       "      <td>2.4G</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-21</th>\n",
       "      <td>2.3G</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-22</th>\n",
       "      <td>1020.1M</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-23</th>\n",
       "      <td>1.5G</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-24</th>\n",
       "      <td>1.5G</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-25</th>\n",
       "      <td>1.7G</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-26</th>\n",
       "      <td>2.3G</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-27</th>\n",
       "      <td>1.6G</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-28</th>\n",
       "      <td>2.2G</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Size Day_Of_Week\n",
       "Day                            \n",
       "2011-09-15   493.9M    Thursday\n",
       "2011-09-16     1.8G      Friday\n",
       "2011-09-17     1.9G    Saturday\n",
       "2011-09-18     2.0G      Sunday\n",
       "2011-09-19     1.7G      Monday\n",
       "2011-09-20     2.2G     Tuesday\n",
       "2011-09-21   388.6M   Wednesday\n",
       "2011-09-23     1.0G      Friday\n",
       "2011-09-24     2.0G    Saturday\n",
       "2011-09-25     2.0G      Sunday\n",
       "2011-09-26     1.9G      Monday\n",
       "2011-09-27     1.7G     Tuesday\n",
       "2011-09-28     1.7G   Wednesday\n",
       "2011-09-29     1.8G    Thursday\n",
       "2011-10-01     1.9G    Saturday\n",
       "2011-10-02     1.8G      Sunday\n",
       "2011-10-03     1.7G      Monday\n",
       "2011-10-04     1.6G     Tuesday\n",
       "2011-10-06   836.8M    Thursday\n",
       "2011-10-09    46.7M      Sunday\n",
       "2011-10-10     1.2G      Monday\n",
       "2011-10-11     1.8G     Tuesday\n",
       "2011-10-12     1.6G   Wednesday\n",
       "2011-10-13     1.8G    Thursday\n",
       "2011-10-14     1.8G      Friday\n",
       "2011-10-15     1.8G    Saturday\n",
       "2011-10-16     1.6G      Sunday\n",
       "2011-10-17     1.2G      Monday\n",
       "2011-10-18     1.5G     Tuesday\n",
       "2011-10-19     2.3G   Wednesday\n",
       "2011-10-20     2.4G    Thursday\n",
       "2011-10-21     2.3G      Friday\n",
       "2011-10-22  1020.1M    Saturday\n",
       "2011-10-23     1.5G      Sunday\n",
       "2011-10-24     1.5G      Monday\n",
       "2011-10-25     1.7G     Tuesday\n",
       "2011-10-26     2.3G   Wednesday\n",
       "2011-10-27     1.6G    Thursday\n",
       "2011-10-28     2.2G      Friday"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats = io.StringIO()\n",
    "buf = \"\"\n",
    "for root, dirs, files in os.walk('/home/dingbat/data/taxi/shenzhen/2011-Shenzhen/data'):\n",
    "    for f in files:\n",
    "        if not f.startswith('.'):\n",
    "            buf += '{},{},{}\\n'.format(\n",
    "                    os.path.splitext(f)[0],\n",
    "                    human_size(os.stat(os.path.join(root, f)).st_size),\n",
    "                    datetime.strptime(os.path.splitext(f)[0], '%Y-%m-%d').strftime(\"%A\")\n",
    "            )\n",
    "csv_buf = io.BytesIO(buf.encode('utf-8'))\n",
    "pd.read_csv(csv_buf, parse_dates='Day', index_col='Day', names=['Day','Size','Day_Of_Week']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations on the Data\n",
    "#### Missing Files\n",
    "\n",
    "Just looking at the filenames we have data between September 15, 2011 and October 28, 2011.  However, the following days are missing.\n",
    "1. 2011-09-22\n",
    "1. 2011-09-30\n",
    "1. 2011-10-05\n",
    "1. 2011-10-07\n",
    "1. 2011-10-08\n",
    "\n",
    "#### Repeated Timestamps\n",
    "Some of the datafiles have duplicate timestamps but the data at each timestamp is different.  Unless a way is determined to choose which file is correct, these data files are unusable.  The files include:\n",
    "1. 2011-09-15.txt\n",
    "1. 2011-10-09.txt\n",
    "\n",
    "#### Significant Dates\n",
    "October 1 - 7 is National Day holiday.  It is the case that workers will instead work Saturday and Sunday on the 8th and 9th to have the holiday off (http://www.startinchina.com/china/public_holidays/2011.html, http://www.shenzhen-standard.com/2011/01/13/2011-public-holidays/).  Classes at Shenzhen University are beginning mid-September (http://www.szu.edu.cn/2014/en/cb/1968.html), which might offer some different travel patterns.  Freshman start Sept 26 but the schedule seems to indicate they arrive on Sept 6.  The mid-autumn fesitival has already concluded (9/10 - 9/12) prior to the start of the data.\n",
    "\n",
    "#### Incomplete Data\n",
    "Of the remaining files, there are some that seem to be missing data as determined by the abnormally small size.  One might expect this is related to holiday or other irregularity.  However, the 'National Day' holiday October 1 - 7 shows that the data size maintains pattern during this time.\n",
    "1. 2011-9-21.txt\n",
    "1. 2011-10-06.txt\n",
    "1. 2011-10-09.txt\n",
    "1. 2011-10-22.txt\n",
    "\n",
    "#### Chinese Map Shift\n",
    "This data applies the Chinese map shift: https://en.wikipedia.org/wiki/Restrictions_on_geographic_data_in_China.  The shift results in the data in China being offset from straight WGS-84 coordinate system employed by GPS and generally translated to mercator projection of the map.  It will appear well on maps that also apply this shift such as Google but will not look good on other maps that consistently use the same projection such as OpenStreetMap.\n",
    "\n",
    "#### Notes\n",
    "In September 2011, Shenzhen introducted a lot of new electric taxis. http://senseable.mit.edu/wef/pdfs/04_SHENZHEN.pdf\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "In other words, there are 39 days of data files but one of the days (2011-9-15) is suspect and should not be used unless a way to reconcile the duplicate timestamp is determined.  An additional 4 days offer incomplete data with one being extremely small size.  This result is about **35 days of good, full data**.  A **complete week's worth of data can be found starting October 10th**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a visual inspection, the columns seem to be in the following format.  There are some unknowns from looking at the data such as what the use of the unknown column might be and whether the Loaded column is accurate.\n",
    "\n",
    "Taxi ID|Longitude|Latitude|UNIX Timestamp|Speed|Heading|Unknown?|Loaded?\n",
    "-------|---------|--------|--------------|-----|-------|-------|--------\n",
    "1046148|113.927121|22.684149|1318206571.000000|22|90|0|0\n",
    "1046148|113.932452|22.681797|1318206661.000000|50|90|0|0\n",
    "1046148|113.934130|22.681058|1318206691.000000|20|90|0|0\n",
    "1046148|113.935274|22.680526|1318206721.000000|22|90|0|0\n",
    "1046148|113.936159|22.680207|1318206751.000000|0|45|0|0\n",
    "1046148|113.936731|22.680116|1318206781.000000|9|90|0|0\n",
    "1046148|113.937006|22.680156|1318206811.000000|0|45|0|0\n",
    "1046148|113.937044|22.680167|1318206841.000000|7|90|0|0\n",
    "1046148|113.938599|22.680173|1318206871.000000|22|45|0|0\n",
    "1046148|113.939461|22.680196|1318206901.000000|31|45|0|0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Initial Conversion\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is much faster to read in the data directly and then perform conversions on the time column using the read in dataframe.  In the next cell the CSV file is being read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:34.846592 to read in 1.2G size data file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>speed</th>\n",
       "      <th>heading</th>\n",
       "      <th>unknown</th>\n",
       "      <th>passenger</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1047839</th>\n",
       "      <th>2011-10-10 14:17:03+08:00</th>\n",
       "      <td>114.122860</td>\n",
       "      <td>22.569472</td>\n",
       "      <td>69</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076787</th>\n",
       "      <th>2011-10-10 10:51:31+08:00</th>\n",
       "      <td>114.212215</td>\n",
       "      <td>22.724362</td>\n",
       "      <td>49</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137048</th>\n",
       "      <th>2011-10-10 07:57:22+08:00</th>\n",
       "      <td>114.118159</td>\n",
       "      <td>22.584978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150513</th>\n",
       "      <th>2011-10-10 01:38:30+08:00</th>\n",
       "      <td>114.654096</td>\n",
       "      <td>23.653488</td>\n",
       "      <td>74</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208242</th>\n",
       "      <th>2011-10-10 12:41:45+08:00</th>\n",
       "      <td>113.955007</td>\n",
       "      <td>22.567787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      longitude   latitude  speed  heading  \\\n",
       "common_id timestamp                                                          \n",
       "1047839   2011-10-10 14:17:03+08:00  114.122860  22.569472     69      180   \n",
       "1076787   2011-10-10 10:51:31+08:00  114.212215  22.724362     49      225   \n",
       "1137048   2011-10-10 07:57:22+08:00  114.118159  22.584978      0        0   \n",
       "1150513   2011-10-10 01:38:30+08:00  114.654096  23.653488     74      180   \n",
       "1208242   2011-10-10 12:41:45+08:00  113.955007  22.567787      0        0   \n",
       "\n",
       "                                     unknown  passenger  \n",
       "common_id timestamp                                      \n",
       "1047839   2011-10-10 14:17:03+08:00        0          0  \n",
       "1076787   2011-10-10 10:51:31+08:00        0          0  \n",
       "1137048   2011-10-10 07:57:22+08:00        0          0  \n",
       "1150513   2011-10-10 01:38:30+08:00        0          0  \n",
       "1208242   2011-10-10 12:41:45+08:00        0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity.loader.taxi.shenzhen import Shenzhen2011\n",
    "\n",
    "taxi_file = '/home/dingbat/data/taxi/shenzhen/2011-Shenzhen/data/201110-Shenzhen/2011-10-10.txt'\n",
    "reader = Shenzhen2011(organization='Hangzhou')\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "df = reader.resource_to_dataframe(taxi_file)\n",
    "\n",
    "print('{} to read in {} size data file'.format(\n",
    "    datetime.now() - start_time,\n",
    "    human_size(os.path.getsize(taxi_file))\n",
    "))\n",
    "\n",
    "sample_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e96001d80ad2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Unshift the data back into WGS-84\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtuple_wgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcj2wgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple_wgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple_wgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/transform.py\u001b[0m in \u001b[0;36mgcj2wgs\u001b[1;34m(gcjLon, gcjLat)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meviltransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcj2wgs_exact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefine_gcj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   3970\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3972\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3973\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3974\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4064\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4066\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/transform.py\u001b[0m in \u001b[0;36mrefine_gcj\u001b[1;34m(sample)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefine_gcj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meviltransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcj2wgs_exact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrefine_gcj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/eviltransform.py\u001b[0m in \u001b[0;36mgcj2wgs_exact\u001b[1;34m(gcjLat, gcjLng, max_iterations, threshold, initDelta)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mwgsLat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmLat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpLat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mwgsLng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmLng\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpLng\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mtmplat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmplng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwgs2gcj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwgsLat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgsLng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mdLat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmplat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgcjLat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdLng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmplng\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgcjLng\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/eviltransform.py\u001b[0m in \u001b[0;36mwgs2gcj\u001b[1;34m(wgsLat, wgsLng)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwgsLat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgsLng\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mdlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwgsLat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgsLng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwgsLat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgsLng\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdlng\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/eviltransform.py\u001b[0m in \u001b[0;36mdelta\u001b[1;34m(lat, lng)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6378245.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mee\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.00669342162296594323\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mdLat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformLat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlng\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m105.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m35.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[0mdLng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformLon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlng\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m105.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m35.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mradLat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlat\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m180.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dingbat/share/src/Taxilytics/research/processing/coordinates/eviltransform.py\u001b[0m in \u001b[0;36mtransformLat\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m             math.sin(y / 3.0 * math.pi)) * 2.0 / 3.0\n\u001b[0;32m     23\u001b[0m     ret += (160.0 * math.sin(y / 12.0 * math.pi) + 320 *\n\u001b[1;32m---> 24\u001b[1;33m             math.sin(y * math.pi / 30.0)) * 2.0 / 3.0\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "# Unshift the data back into WGS-84\n",
    "tuple_wgs = gcj2wgs(df.loc[:,'longitude'], df.loc[:,'latitude'])\n",
    "df.loc[:,'longitude'] = tuple_wgs[0]\n",
    "df.loc[:,'latitude'] = tuple_wgs[1]\n",
    "print('{} to unshift data points'.format(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "df = remove_safe_dups(df)  # Remove rows where all data is the same\n",
    "df = remove_impossible(df)  # Remove rows with data that is impossible\n",
    "df = df[~df.index.duplicated()] # Remove rows where the index is the same, keeps the first instance\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print('{} to filter and sort'.format(datetime.now() - start_time))\n",
    "df.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on the data\n",
    "To view some additional information surrounding the data, print a couple statistical tables such as the data types used on each column and general statistics about the data.  One fundamental attribute is the time bounds of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index.levels[0].min(), df.index.levels[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index.levels[1].min(), df.index.levels[1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning the data\n",
    "Now let's look at splitting up the data to get individual taxis and even individual trips for those taxis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition by taxi\n",
    "Using the groupby method the big datafile can be broken down into individual taxis and the sub-dataframe accessed using the get_group method.  More generally, the entire set of taxis can be iterated using the grouped object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi_partitions = df.groupby(level='common_id', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_df(taxi_partitions.get_group(1211897))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for common_id, taxi_data in taxi_partitions:\n",
    "    taxi_data.index = taxi_data.index.droplevel(0)\n",
    "    taxi_data = remove_implausible(taxi_data)  # Removes points that are implausible such as traveling too fast\n",
    "    break\n",
    "print('Taxi ID: {}'.format(common_id))\n",
    "sample_df(taxi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Taxi by Trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some reasonably good data identified, we can split the taxi into trips.  The following partitioning is done using the passenger status such that each time the passenger status changes, a new trip is created.  In order to maintain continuity between the partitions, the first point of the subsequent trip is used as the last point of the current trip.\n",
    "\n",
    "In order to partition the trips by the passenger status, a temporary series can be created as a shifted status and then the changes in the status change added up to label each trip.  The trip ID is added to the taxi DataFrame to enable the pandas groupby functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since the column is already a flag it can be used directly.  Otherwise, this would convert it to a flag.\n",
    "# trips = (taxi.passenger - taxi.passenger.shift(1)).cumsum()\n",
    "for common_id, taxi_data in taxi_partitions:\n",
    "    taxi_data.index = taxi_data.index.droplevel(0)\n",
    "    trips = (taxi_data.passenger.diff(1) != 0).astype('int').cumsum()\n",
    "    trip_groups = taxi_data.groupby(trips, sort=False)\n",
    "    if len(trip_groups) > 1:\n",
    "        taxi_data = remove_implausible(taxi_data)  # Removes points that are implausible such as traveling too fast\n",
    "        break\n",
    "sample_df(trips, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the trips can be iterated to integrate into the functionality for other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trip_groups = taxi_data.groupby(trips, sort=False)\n",
    "def print_trip(trip):\n",
    "    start_time = trip.index[0]\n",
    "    end_time = trip.index[-1]\n",
    "    passenger = '- Passenger' if trip.passenger[0] else ''\n",
    "    print('Start({}): Duration({}): Samples({}){}'.format(\n",
    "        start_time, end_time - start_time, len(trip) + 1, passenger\n",
    "    ))\n",
    "\n",
    "prev_seq = None\n",
    "for name, trip in trip_groups:\n",
    "    if prev_seq is not None:\n",
    "        # Trip from beginning of previous sequence through first point of current.\n",
    "        combined = pd.concat([prev_seq, trip.iloc[:1]])\n",
    "        print_trip(combined)\n",
    "    prev_seq = trip\n",
    "print_trip(prev_seq)  # Last trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating the Coordinate System\n",
    "This part shifts the data to the WGS-84 representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from entity.loader.taxi.taxi_common import create_linestring\n",
    "data_gcj = prev_seq\n",
    "data_wgs = prev_seq.copy()\n",
    "start_time = datetime.now()\n",
    "tuple_wgs = gcj2wgs(prev_seq.loc[:,'longitude'], prev_seq.loc[:,'latitude'])\n",
    "data_wgs.loc[:,'longitude'] = tuple_wgs[0]\n",
    "data_wgs.loc[:,'latitude'] = tuple_wgs[1]\n",
    "print('{} to convert to WGS-84'.format(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(\"Shifted\")\n",
    "display(data_gcj[:5])\n",
    "display(\"Unshifted\")\n",
    "display(data_wgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geojson, json\n",
    "feature_gcj = geojson.Feature(id='0', geometry=json.loads(create_linestring(data_gcj).json))\n",
    "feature_wgs = geojson.Feature(id='1', geometry=json.loads(create_linestring(data_wgs).json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var ss = document.createElement(\"link\");\n",
    "ss.type = \"text/css\";\n",
    "ss.rel = \"stylesheet\";\n",
    "ss.href = '../tree/entity/static/entity/css/ol.css';\n",
    "document.getElementsByTagName(\"head\")[0].appendChild(ss);\n",
    "element.append(\"<div id='content'></div>\");\n",
    "element.append(\"<h3 align='center'>Red is 'shifted'<BR>Green is 'unshifted' WGS-84</h3>\");\n",
    "require.config({\n",
    "    'baseUrl': '/',\n",
    "    paths : {\n",
    "        \"entity/js/ol\": \"tree/entity/static/entity/js/ol\",\n",
    "        \"entity/js/map\": \"tree/entity/static/entity/js/map\",\n",
    "        \"entity/js/color\": \"tree/entity/static/entity/js/color\",\n",
    "        \"js/3rdparty/tinycolor\": \"tree/static/js/3rdparty/tinycolor\"\n",
    "    },\n",
    "    shim: {\n",
    "        \"js/3rdparty/tinycolor\": {\"exports\": \"tinycolor\"},\n",
    "        \"ol\": {\"exports\": \"ol\"},\n",
    "    }\n",
    "});\n",
    "require(['tree/entity/static/entity/js/map'], function(map) {\n",
    "        function callback(msg, element_name) {\n",
    "            map.setData(JSON.parse(msg.content.data[\"text/plain\"].replace(/\\'/g, \"\")));\n",
    "        }\n",
    "        map.init()\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute(\"feature_wgs\", {iopub: {output: callback}}, {silent:false});\n",
    "        kernel.execute(\"feature_gcj\", {iopub: {output: callback}}, {silent:false});\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "It appears that the new Shenzhen data (i.e. for the year 2011) can be 'unshifted' to put it back into WGS-84 so that it matches up to the map."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
