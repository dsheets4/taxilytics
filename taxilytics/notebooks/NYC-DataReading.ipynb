{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC T&LC Data\n",
    "\n",
    "## Size\n",
    "The size of the data is summarized in the following table, with a grand total shown in the lower right (1.2 billion):\n",
    "\n",
    "Year|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec|Total Result\n",
    "-|-:|-:|-:|-:|-:|-:|-:|-:|-:|-:|-:|-:|-:\n",
    "2009|1.41E+7|1.34E+7|1.44E+7|1.43E+7|1.48E+7|1.42E+7|1.36E+7|1.37E+7|1.40E+7|1.56E+7|1.43E+7|1.46E+7|1.71E+8\n",
    "2010|1.49E+7|1.11E+7|1.29E+7|1.51E+7|1.55E+7|1.48E+7|1.47E+7|1.25E+7|1.55E+7|1.42E+7|1.39E+7|1.38E+7|1.69E+8\n",
    "2011|1.35E+7|1.42E+7|1.61E+7|1.47E+7|1.56E+7|1.51E+7|1.47E+7|1.33E+7|1.46E+7|1.57E+7|1.45E+7|1.49E+7|1.77E+8\n",
    "2012|1.50E+7|1.50E+7|1.61E+7|1.55E+7|1.56E+7|1.51E+7|1.44E+7|1.44E+7|1.45E+7|1.45E+7|5.16E+6|1.47E+7|1.70E+8\n",
    "2013|1.48E+7|1.40E+7|1.57E+7|1.51E+7|1.53E+7|1.44E+7|1.38E+7|1.26E+7|1.42E+7|1.52E+7|1.48E+7|1.46E+7|1.74E+8\n",
    "2014|1.46E+7|1.41E+7|1.67E+7|1.59E+7|1.62E+7|1.52E+7|1.44E+7|1.40E+7|1.47E+7|1.57E+7|1.48E+7|1.47E+7|1.81E+8\n",
    "2015|1.43E+7|1.40E+7|1.51E+7|1.47E+7|1.49E+7|1.40E+7|1.31E+7|1.27E+7|1.27E+7|1.39E+7|1.28E+7|1.31E+7|1.65E+8\n",
    "Total Result|1.01E+8|9.58E+7|1.07E+8|1.05E+8|1.08E+8|1.03E+8|9.87E+7|9.32E+7|1.00E+8|1.05E+8|9.03E+7|1.00E+8|**1.21E+9**\n",
    "\n",
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Comparison\n",
    "The raw data is CSV using DOS line terminators.  The table below lists both data formats and the corresponding column number and parameter name in each.  Such a table is useful for configuring things like awk or other data reading features.\n",
    "\n",
    "|Column|Yellow|Green|\n",
    "|-|-|-|\n",
    "|1|VendorID              |VendorID\n",
    "|2|tpep_pickup_datetime  |lpep_pickup_datetime\n",
    "|3|tpep_dropoff_datetime |Lpep_dropoff_datetime\n",
    "|4|**passenger_count**   |**Store_and_fwd_flag**\n",
    "|5|**trip_distance**     |**RateCodeID**\n",
    "|6|pickup_longitude      |Pickup_longitude\n",
    "|7|pickup_latitude       |Pickup_latitude\n",
    "|8|**RateCodeID**        |**Dropoff_longitude**\n",
    "|9|**store_and_fwd_flag**|**Dropoff_latitude**\n",
    "|10|**dropoff_longitude**|**Passenger_count**\n",
    "|11|**dropoff_latitude** |**Trip_distance**\n",
    "|12|**payment_type**     |**Fare_amount**\n",
    "|13|**fare_amount**      |**Extra**\n",
    "|14|**extra**            |**MTA_tax**\n",
    "|15|**mta_tax**          |**Tip_amount**\n",
    "|16|**tip_amount**       |**Tolls_amount**\n",
    "|17|**tolls_amount**     |**Ehail_fee**\n",
    "|18|improvement_surcharge|improvement_surcharge\n",
    "|19|total_amount         |Total_amount\n",
    "|20|                     |**Payment_type**\n",
    "|21|                     |**Trip_type**\n",
    "\n",
    "The bash script below performs an initial translation of the data into the data schema being used for trips.  The output from that script is much larger due to the JSON data but the file itself is consumable using the COPY command in PostGreSQL, which makes it orders of magnitude faster.  The script performs the following:\n",
    "\n",
    "1. Expand the given input data file to an absolute path (for traceability)\n",
    "1. Strip the header row from the top of the file via tail -n +2\n",
    "1. Remove the carriage return via dos2unix\n",
    "1. Convert the original file format to the desired format using awk\n",
    "1. Removes any records where the positional information is 0\n",
    "\n",
    "The fields for a trip in the database fields are described below:\n",
    "1. **id**: Skipping this in the COPY FROM command results in the database assigning the default, which is what is desired.\n",
    "1. **entity**: This will be NULL for NYC T&LC data\n",
    "1. **start_datetime** = models.DateTimeField()\n",
    "1. **duration** = models.DurationField()\n",
    "1. **geometry** = models.LineStringField(dim=3, null=True)\n",
    "1. **metadata** = JsonBField()\n",
    "1. **archive_uri** = models.CharField(max_length=1024)\n",
    "\n",
    "If the COPY command does not receive an input for a column it will use any defined default or not work if the field is required.  This works to our benefit in the case of the id, which is defined to always get a unique identifier.  The code below will bulk load a single file into the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Use shell commands to convert the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyc_parse_config = {\n",
    "    'yellow_v1': {\n",
    "        'pattern': 'yellow_tripdata_(2009|201[0-4])',\n",
    "        'columns': {\n",
    "            'passenger_count': '$4',\n",
    "            'trip_dist': '$5',\n",
    "            'pu_lon': '$6',\n",
    "            'pu_lat': '$7',\n",
    "            'do_lon': '$10',\n",
    "            'do_lat': '$11',\n",
    "            'rate_code': '$8',\n",
    "            'store_fwd_flag': '$9',\n",
    "            'pay_type': '$12',\n",
    "            'fare_amount': '$13',\n",
    "            'extra': '$14',\n",
    "            'mta_tax': '$15',\n",
    "            'imp_charge': '0',\n",
    "            'tip_amount': '$16',\n",
    "            'tolls_amount': '$17',\n",
    "            'ehail_fee': 0,\n",
    "            'total_amount': '$18',\n",
    "            'trip_type': \"Unknown\",\n",
    "            'taxi_type': 'yellow',\n",
    "            'fields': 18\n",
    "        },\n",
    "    },\n",
    "    'yellow_v2': {\n",
    "        'pattern': 'yellow_tripdata_(2015|2016-(0[1-6]))',\n",
    "        'columns': {\n",
    "            'passenger_count': '$4',\n",
    "            'trip_dist': '$5',\n",
    "            'pu_lon': '$6',\n",
    "            'pu_lat': '$7',\n",
    "            'do_lon': '$10',\n",
    "            'do_lat': '$11',\n",
    "            'rate_code': '$8',\n",
    "            'store_fwd_flag': '$9',\n",
    "            'pay_type': '$12',\n",
    "            'fare_amount': '$13',\n",
    "            'extra': '$14',\n",
    "            'mta_tax': '$15',\n",
    "            'imp_charge': '$18',\n",
    "            'tip_amount': '$16',\n",
    "            'tolls_amount': '$17',\n",
    "            'ehail_fee': 0,\n",
    "            'total_amount': '$19',\n",
    "            'trip_type': \"Unknown\",\n",
    "            'taxi_type': 'yellow',\n",
    "            'fields': 19\n",
    "        },\n",
    "    },\n",
    "    # 'yellow_v3': {\n",
    "    #     'pattern': 'yellow_tripdata_2016-(0[7-9]|1[0-2])',\n",
    "    #     'columns': {\n",
    "    #         # Pickup and Dropoff locations change to areas, requires revision of data model\n",
    "    #     },\n",
    "    # },\n",
    "    'green_v1': {\n",
    "        'pattern': 'green_tripdata_(2009|201[0-4])',\n",
    "        'columns': {\n",
    "            'passenger_count': '$10',\n",
    "            'trip_dist': '$11',\n",
    "            'pu_lon': '$6',\n",
    "            'pu_lat': '$7',\n",
    "            'do_lon': '$8',\n",
    "            'do_lat': '$9',\n",
    "            'rate_code': '$5',\n",
    "            'store_fwd_flag': '$4',\n",
    "            'pay_type': '$19',\n",
    "            'fare_amount': '$12',\n",
    "            'extra': '$13',\n",
    "            'mta_tax': '$14',\n",
    "            'imp_charge': 0,\n",
    "            'tip_amount': '$15',\n",
    "            'tolls_amount': '$16',\n",
    "            'ehail_fee': '$17',\n",
    "            'total_amount': '$18',\n",
    "            'trip_type': '$20',\n",
    "            'taxi_type': 'green',\n",
    "            'fields': 20\n",
    "        },\n",
    "    },\n",
    "    'green_v2': {\n",
    "        'pattern': 'green_tripdata_(2015|2016-(0[1-6]))',\n",
    "        'columns': {\n",
    "            'passenger_count': '$10',\n",
    "            'trip_dist': '$11',\n",
    "            'pu_lon': '$6',\n",
    "            'pu_lat': '$7',\n",
    "            'do_lon': '$8',\n",
    "            'do_lat': '$9',\n",
    "            'rate_code': '$5',\n",
    "            'store_fwd_flag': '$4',\n",
    "            'pay_type': '$20',\n",
    "            'fare_amount': '$12',\n",
    "            'extra': '$13',\n",
    "            'mta_tax': '$14',\n",
    "            'imp_charge': '$18',\n",
    "            'tip_amount': '$15',\n",
    "            'tolls_amount': '$16',\n",
    "            'ehail_fee': '$17',\n",
    "            'total_amount': '$19',\n",
    "            'trip_type': '$21',\n",
    "            'taxi_type': 'green',\n",
    "            'fields': 21\n",
    "        },\n",
    "    },\n",
    "    # 'green_v3': {\n",
    "    #     'pattern': 'green_tripdata_2016-(0[7-9]|1[0-2])',\n",
    "    #     'columns': {\n",
    "    #         # Pickup and Dropoff locations change to areas, requires revision of data model\n",
    "    #     },\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "awk_template=dedent(\"\"\"\\\n",
    "            BEGIN {{ FS = \",\"; OFS = \"|\"}}\n",
    "            {{\n",
    "                if ( NR == 1 ) {{\n",
    "                    print $0 > \"/dev/stderr\"\n",
    "                    next\n",
    "                }}\n",
    "                if (/^\\s*$/ ) {{ next; }}\n",
    "                if ( {pu_lon} == \"0\" || {pu_lat} == \"0\" || {do_lon} == \"0\" || {do_lat} == \"0\" ) {{\n",
    "                    print \"Invalid position \" FILENAME \"(\" NR \"): \" $0 > \"/dev/stderr\"\n",
    "                    next\n",
    "                }}\n",
    "                match($2, /^([0-9]{{4}})-([0-9]{{2}}).*/, ymd)\n",
    "                t1 = gensub(/[-:]/,\" \",\"g\",$2);\n",
    "                t2 = gensub(/[-:]/,\" \",\"g\",$3);\n",
    "                d1=mktime(t1);\n",
    "                d2=mktime(t2);\n",
    "                if ( d2-d1 > 1000000 ) {{\n",
    "                    print \"Invalid timestamp \" FILENAME \"(\" NR \"): \" $0 > \"/dev/stderr\"\n",
    "                    next\n",
    "                }}\n",
    "                gsub(/\\r/, \"\", $NF);\n",
    "\n",
    "                if( $1==1 || $1==\"CMT\" ) vendor=\"Creative Mobile Technologies, LLC\";\n",
    "                else if( $1==2 || $1==\"VTS\" ) vendor=\"VeriFone Inc.\";\n",
    "                else if( $1==\"DDS\" ) vendor=\"Digital Dispatch Systems Inc.\";\n",
    "                else vendor=$1;\n",
    "\n",
    "                py = toupper({pay_type})\n",
    "                if( py==\"2\" || py==\"CASH\" || py==\"CAS\" || py==\"CSH\" ) payment=\"Cash\"\n",
    "                else if( py==\"1\" || py==\"CRD\" || py==\"CRE\" || py==\"CREDIT\" ) payment=\"Credit\"\n",
    "                else if( py==\"3\" ) payment=\"No Charge\"\n",
    "                else if( py==\"4\" ) payment=\"Dispute\"\n",
    "                else if( py==\"5\" ) payment=\"Unknown\"\n",
    "                else if( py==\"6\" ) payment=\"Voided Trip\"\n",
    "                else payment={pay_type}\n",
    "\n",
    "                if( {rate_code}==1 ) rate=\"Standard rate\"\n",
    "                else if( {rate_code}==2 ) rate=\"JFK\"\n",
    "                else if( {rate_code}==3 ) rate=\"Newark\"\n",
    "                else if( {rate_code}==4 ) rate=\"Nassau or Westchester\"\n",
    "                else if( {rate_code}==5 ) rate=\"Negotiated fare\"\n",
    "                else if( {rate_code}==6 ) rate=\"Group ride\"\n",
    "                else rate={rate_code}\n",
    "\n",
    "                if( {trip_type}==1 ) tt=\"Street-hail\"\n",
    "                else if( {trip_type}==2 ) tt=\"Dispatch\"\n",
    "                else tt={trip_type}\n",
    "\n",
    "                if( {store_fwd_flag}==\"Y\" ) sf=\"true\";\n",
    "                else sf=\"false\";\n",
    "\n",
    "                row_id=sprintf(\"%d\", ((ymd[1]-2000)*100+ymd[2])) sprintf(\"%015d\", FNR)\n",
    "\n",
    "                print row_id, $2, d2-d1, \"SRID=4326;LINESTRING(\" {pu_lon} \" \" {pu_lat} \" 0,\" {do_lon} \" \" {do_lat} \" \" d2-d1 \")\", FILENAME\"?line=\"NR, \\\\\n",
    "                    \"{{\"\\\\\n",
    "                        \"\\\\\"vendor\\\\\":\" \"\\\\\"\"vendor\"\\\\\"\" \\\\\n",
    "                        \",\\\\\"trip_distance\\\\\":\" sprintf(\"%g\", {trip_dist}) \\\\\n",
    "                        \",\\\\\"passenger_count\\\\\":\" {passenger_count} \\\\\n",
    "                        \",\\\\\"rate\\\\\":\"  \"\\\\\"\"rate\"\\\\\"\" \\\\\n",
    "                        \",\\\\\"fare_amount\\\\\":\" sprintf(\"%.2f\", {fare_amount}) \\\\\n",
    "                        \",\\\\\"mta_tax\\\\\":\" sprintf(\"%.2f\", {mta_tax}) \\\\\n",
    "                        \",\\\\\"tip_amount\\\\\":\" sprintf(\"%.2f\", {tip_amount}) \\\\\n",
    "                        \",\\\\\"tolls_amount\\\\\":\" sprintf(\"%.2f\", {tolls_amount}) \\\\\n",
    "                        \",\\\\\"ehail_fee\\\\\":\" sprintf(\"%.2f\", {ehail_fee}) \\\\\n",
    "                        \",\\\\\"extra\\\\\":\" sprintf(\"%.2f\", {extra}) \\\\\n",
    "                        \",\\\\\"improvement_surcharge\\\\\":\" sprintf(\"%.2f\", {imp_charge}) \\\\\n",
    "                        \",\\\\\"total_amount\\\\\":\" sprintf(\"%.2f\", {total_amount}) \\\\\n",
    "                        \",\\\\\"payment_type\\\\\":\" \"\\\\\"\"payment\"\\\\\"\" \\\\\n",
    "                        \",\\\\\"store_and_fwd_flag\\\\\":\" sf \\\\\n",
    "                        \",\\\\\"trip_type\\\\\":\" \"\\\\\"\"tt\"\\\\\"\" \\\\\n",
    "                        \",\\\\\"taxi_type\\\\\": \\\\\"{taxi_type}\\\\\"\" \\\\\n",
    "                    \"}}\"\n",
    "            }}\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk_script = awk_template.format(**nyc_parse_config['green_v2']['columns'])\n",
    "with open('/home/dingbat/data/taxi/NYCTLC/taxi.awk', 'w') as f:\n",
    "    f.write(awk_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling awk from python and streaming results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from django.db import connections\n",
    "\n",
    "\n",
    "if True:\n",
    "    ifilename = '/home/dingbat/data/taxi/NYCTLC/yellow_tripdata_2009-01-sample.csv'\n",
    "else:\n",
    "    ifilename = '/home/dingbat/data/taxi/NYC/DataNYCTLC/2015/yellow/yellow_tripdata_2015-01.csv'\n",
    "\n",
    "awk_script = awk_template.format(**nyc_parse_config['yellow_v2']['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('id_split.py', 'w') as f:\n",
    "    f.write(dedent(\"\"\"\\\n",
    "        import sys\n",
    "        ids = []\n",
    "        for line in sys.stdin:\n",
    "            split_line = line.split('|', 1)\n",
    "            ids.append(split_line[0])\n",
    "            print(line)\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database load: Start=2016-03-27 00:57:03.537268; End=2016-03-27 00:57:03.559222\n",
      "Created 34 records in 0:00:00.021954s\n"
     ]
    }
   ],
   "source": [
    "from django.db import transaction\n",
    "from entity.models import Trip\n",
    "from contextlib import closing\n",
    "from django.db import connection\n",
    "import subprocess\n",
    "import os\n",
    "import io\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Create a stream from the shell commands for use with copy_expert.\n",
    "ifilename = os.path.abspath(ifilename)\n",
    "ps_awk = subprocess.Popen(\n",
    "    ['awk', '-v', 'f={}'.format(ifilename), awk_script, ifilename],\n",
    "    stdout=subprocess.PIPE\n",
    ")\n",
    "ps_awk = subprocess.Popen(\n",
    "    ['awk', '-v', 'f={}'.format(ifilename), awk_script, ifilename],\n",
    "    stdout=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Read in the stream to the database.\n",
    "cursor = connections['default'].cursor()\n",
    "cursor.copy_expert(\n",
    "    \"COPY entity_trip(start_datetime, duration, geometry, archive_uri, metadata) FROM STDOUT DELIMITER '|'\",\n",
    "    file=ps_awk.stdout\n",
    ")\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "print('Database load: Start={}; End={}'.format(start, end))\n",
    "print('Created {:,} records in {}s'.format(cursor.rowcount, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Removed 71502 invalid rows in 0:01:12.633380'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove trajectories that are outside of the valid region or invalid for some reason (usually same start and end point)\n",
    "start = datetime.now()\n",
    "cursor.execute(\"\"\"\n",
    "    DELETE FROM entity_trip\n",
    "    WHERE\n",
    "        NOT ST_GeomFromText('POLYGON((-180 -90, 180 -90, 180 90, -180 90, -180 -90))') ~ geometry\n",
    "        OR\n",
    "        NOT ST_IsValid(geometry)\n",
    "    \"\"\".replace('\\n', ' '))\n",
    "'Removed {} invalid rows in {}'.format(cursor.rowcount, datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP FUNCTION IF EXISTS osm_roadmatch_line(geometry, int);\")\n",
    "cursor.execute(\"DROP FUNCTION IF EXISTS osm_roadmatch_point(geometry, int);\")\n",
    "\n",
    "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS hstore;\")\n",
    "cursor.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION osm_roadmatch_point(\n",
    "    point geometry,\n",
    "    initial_results integer DEFAULT 10)\n",
    "RETURNS bigint AS $BODY$\n",
    "DECLARE\n",
    "    the_match bigint;\n",
    "BEGIN\n",
    "    point := ST_Transform(point, 3857);\n",
    "    SELECT l.gid, ST_Distance(l.way, point) as dist\n",
    "    INTO the_match\n",
    "    FROM planet_osm_line as l \n",
    "    WHERE\n",
    "        ST_DWithin(point, l.way, 20)\n",
    "        AND\n",
    "        l.highway IN (\n",
    "            'motorway',\n",
    "            'trunk',\n",
    "            'primary',\n",
    "            'secondary',\n",
    "            'tertiary',\n",
    "            'unclassified',\n",
    "            'residential',\n",
    "            'service',\n",
    "            'motorway_link',\n",
    "            'trunk_link',\n",
    "            'primary_link',\n",
    "            'secondary_link',\n",
    "            'tertiary_link',\n",
    "            'living_street',\n",
    "            'road',\n",
    "            'turning_circle'\n",
    "        )\n",
    "    ORDER BY dist\n",
    "    LIMIT initial_results;\n",
    "    RETURN the_match;\n",
    "END $BODY$\n",
    "LANGUAGE plpgsql VOLATILE;\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE FUNCTION osm_roadmatch_line(\n",
    "    IN geometry,\n",
    "    initial_results int DEFAULT 10)\n",
    "RETURNS bigint[] AS $BODY$\n",
    "DECLARE\n",
    "    roadmatch bigint[];\n",
    "BEGIN\n",
    "    SELECT array_agg(osm_roadmatch_point((dp).geom, initial_results)) INTO roadmatch\n",
    "    FROM (SELECT ST_DumpPoints($1) AS dp) As foo;\n",
    "    RETURN roadmatch;\n",
    "END $BODY$\n",
    "LANGUAGE plpgsql VOLATILE;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Found 0 rows in 0:00:00.002384'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the road matching query.\n",
    "start = datetime.now()\n",
    "cursor.execute(\"\"\"\n",
    "WITH roadmatch_metadata AS (\n",
    "    WITH expanded_json_keys AS (\n",
    "        WITH roadmatch_all AS (\n",
    "            SELECT\n",
    "                id\n",
    "                , osm_roadmatch_line(geometry) as matches\n",
    "                , metadata\n",
    "            FROM entity_trip\n",
    "            WHERE\n",
    "                NOT metadata ? 'roadmatch'\n",
    "                AND\n",
    "                id BETWEEN 0 AND 1000\n",
    "        )\n",
    "        SELECT id, j1.key, j1.value FROM roadmatch_all, jsonb_each(metadata) as j1\n",
    "        UNION\n",
    "        SELECT id, 'roadmatch', to_json(roadmatch_all.matches)::jsonb FROM roadmatch_all\n",
    "    )\n",
    "    SELECT\n",
    "        id,\n",
    "        json_object_agg(key, value)::jsonb as metadata\n",
    "    FROM expanded_json_keys\n",
    "    GROUP BY id\n",
    ")\n",
    "SELECT * FROM roadmatch_metadata\n",
    "\"\"\".replace('\\n', ' '))\n",
    "print(cursor.fetchone())\n",
    "'Found {} rows in {}'.format(cursor.rowcount, datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roadmatched 0 rows in 0:00:00.002572'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the road matching query.\n",
    "start = datetime.now()\n",
    "cursor.execute(\"\"\"\n",
    "WITH roadmatch_metadata AS (\n",
    "    WITH expanded_json_keys AS (\n",
    "        WITH roadmatch_all AS (\n",
    "            SELECT\n",
    "                id\n",
    "                , osm_roadmatch_line(geometry) as matches\n",
    "                , metadata\n",
    "            FROM entity_trip\n",
    "            WHERE\n",
    "                NOT metadata ? 'roadmatch'\n",
    "                AND\n",
    "                id BETWEEN 20000 AND 21000\n",
    "        )\n",
    "        SELECT id, j1.key, j1.value FROM roadmatch_all, jsonb_each(metadata) as j1\n",
    "        UNION\n",
    "        SELECT id, 'roadmatch', to_json(roadmatch_all.matches)::jsonb FROM roadmatch_all\n",
    "    )\n",
    "    SELECT\n",
    "        id,\n",
    "        json_object_agg(key, value)::jsonb as metadata\n",
    "    FROM expanded_json_keys\n",
    "    GROUP BY id\n",
    ")\n",
    "UPDATE entity_trip\n",
    "SET metadata=roadmatch_metadata.metadata\n",
    "FROM roadmatch_metadata\n",
    "WHERE entity_trip.id=roadmatch_metadata.id\n",
    "\"\"\".replace('\\n', ' '))\n",
    "'Roadmatched {} rows in {}'.format(cursor.rowcount, datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.postgresql.org/docs/9.4/interactive/populate.html\n",
    "* http://stefano.dissegna.me/django-pg-bulk-insert.html\n",
    "* https://wiki.postgresql.org/wiki/COPY\n",
    "* http://initd.org/psycopg/docs/cursor.html#cursor.copy_expert\n",
    "* http://adpgtech.blogspot.com/2014/09/importing-json-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
