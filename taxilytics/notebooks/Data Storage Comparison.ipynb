{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "Compare storage techniques for time series data.\n",
    "\n",
    "## Techniques\n",
    "### Serialized Pandas DataFrames\n",
    "Data is stored in the database as binary data in the form of pickle pandas DataFrames.  This allows heterogeneous data storage where the timestamps, numeric, and textual data is all stored in the same data structure.  Queries where a client wishes to run analysis on the data can be done by pulling the data directly but slicing the data frame server side requires unpickling, slicing, then repickling.  This technique is better suited for growth into Big Data techniques than the other techniques but still suffers from the fact that ultimately supporting a pickled binary format covers less ideal situations than a regular binary format such as HDF5, which supports similar data storage techniques (pandas can be serialized to HDF5 through native functions).\n",
    "\n",
    "### Arrays of records\n",
    "Data is stored using the postgres Array as an array of records.  Since data types can't be mixed this requires that timestamp data is stored separately from the data.  Different tables are requried for floating point, integer, and string data.  Data is stored in a native postgres format so querying and analysis server-side should be easier.  Postgres functions can be written to create DataFrames to be sent to a client for analysis client side.  This has some potential benefits when using multiple values on the array since both values at the same time are stored as a sub-array, which reduces the required number of iterations through the data.  This potentially makes database queries faster.\n",
    "\n",
    "### Arrays of series\n",
    "This structure better matches the inputs to create data frames than the \"Array of records\" approach discussed above.  That would make creating pandas data frames more efficient.  However, to perform analysis of multiple values, additional correlation is required.\n",
    "\n",
    "## Tasks\n",
    "* Task 1.1. Query all values of one parameter with time.\n",
    "* Task 1.2. Query a slice of all values of one parameter by time.\n",
    "* Task 2.1. Query multiple values correlated with time.\n",
    "* Task 2.2. Query a slice of time with multuple values and time.\n",
    "* Task 3.1. Combine multiple values at offset timestamps using interpolation techniques.\n",
    "* Task X. Perform roadmatching with latitude and longitude.\n",
    "* Task X. Store non-timestamped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports to assist with reading data files and querying the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from taxidb import execute, format_results  # Functions reused among database query notebooks\n",
    "from entity.loader.taxi import Shenzhen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect statistics on the input database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "num_trips, num_samples = 17385125, 288284766"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT\n",
    "    COUNT(geometry) AS \"num_trips\",\n",
    "    SUM(ST_NPoints(geometry)) AS \"num_samples\"\n",
    "FROM entity_trip\n",
    "\"\"\"\n",
    "format_results(execute(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "sum = 2139681480"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    SELECT\n",
    "        sum((measures->'speed'->>'count')::int)\n",
    "    FROM streetcube_streettaxicell\n",
    "\"\"\"\n",
    "format_results(execute(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = Shenzhen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Organization: Shenzhen>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>passenger</th>\n",
       "      <th>speed</th>\n",
       "      <th>heading</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B40P00</th>\n",
       "      <th>2012-06-27 00:01:46+08:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.541918</td>\n",
       "      <td>114.110046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCC661</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>180</td>\n",
       "      <td>22.649248</td>\n",
       "      <td>113.824486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKS991</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>315</td>\n",
       "      <td>23.087866</td>\n",
       "      <td>113.673447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBZ910</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.858015</td>\n",
       "      <td>113.843796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBS623</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>22.988150</td>\n",
       "      <td>113.701981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBR001</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>23.034866</td>\n",
       "      <td>113.761200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SLP610</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.906050</td>\n",
       "      <td>114.062347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBZ205</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>23.018200</td>\n",
       "      <td>114.092865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBG776</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.982033</td>\n",
       "      <td>113.998901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKZ403</th>\n",
       "      <th>2012-06-27 00:01:39+08:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.040434</td>\n",
       "      <td>113.773163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     passenger  speed  heading   latitude  \\\n",
       "common_id timestamp                                                         \n",
       "B40P00    2012-06-27 00:01:46+08:00          1      0        0  22.541918   \n",
       "SCC661    2012-06-27 00:01:39+08:00          0     55      180  22.649248   \n",
       "SKS991    2012-06-27 00:01:39+08:00          0     85      315  23.087866   \n",
       "SBZ910    2012-06-27 00:01:39+08:00          0      0        0  22.858015   \n",
       "SBS623    2012-06-27 00:01:39+08:00          0      0      270  22.988150   \n",
       "SBR001    2012-06-27 00:01:39+08:00          0      0      270  23.034866   \n",
       "SLP610    2012-06-27 00:01:39+08:00          1      0        0  22.906050   \n",
       "SBZ205    2012-06-27 00:01:39+08:00          0     22      135  23.018200   \n",
       "SBG776    2012-06-27 00:01:39+08:00          0      0        0  22.982033   \n",
       "SKZ403    2012-06-27 00:01:39+08:00          0      0        0  23.040434   \n",
       "\n",
       "                                      longitude  \n",
       "common_id timestamp                              \n",
       "B40P00    2012-06-27 00:01:46+08:00  114.110046  \n",
       "SCC661    2012-06-27 00:01:39+08:00  113.824486  \n",
       "SKS991    2012-06-27 00:01:39+08:00  113.673447  \n",
       "SBZ910    2012-06-27 00:01:39+08:00  113.843796  \n",
       "SBS623    2012-06-27 00:01:39+08:00  113.701981  \n",
       "SBR001    2012-06-27 00:01:39+08:00  113.761200  \n",
       "SLP610    2012-06-27 00:01:39+08:00  114.062347  \n",
       "SBZ205    2012-06-27 00:01:39+08:00  114.092865  \n",
       "SBG776    2012-06-27 00:01:39+08:00  113.998901  \n",
       "SKZ403    2012-06-27 00:01:39+08:00  113.773163  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "shenzhen_data = '/home/dingbat/data/taxi/shenzhen/2012-Shenzhen'\n",
    "df = loader.resource_to_dataframe(os.path.join(shenzhen_data, '2012-06-27.good.sample'))\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "def to_h5(df):\n",
    "    h5 = pd.HDFStore(\n",
    "        uuid.uuid1().hex,\n",
    "        mode='w',\n",
    "        driver=\"H5FD_CORE\",\n",
    "        driver_core_backing_store=0\n",
    "    )\n",
    "    df.to_hdf(h5, 'df')\n",
    "    return h5._handle.get_file_image()\n",
    "\n",
    "def from_h5(h5):\n",
    "    tables.open_file(\"in-memory-sample.h5\", driver=\"H5FD_CORE\",\n",
    "                              driver_core_image=image,\n",
    "                              driver_core_backing_store=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 123 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit to_h5(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def to_pickle(df):\n",
    "    return pickle.dumps(df, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 26.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit to_pickle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
